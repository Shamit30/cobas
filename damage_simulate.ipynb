{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shamit/Documents/Projects/RA/cobas/cobas/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shamit/Documents/Projects/RA/cobas/cobas/venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Loss: 0.8939\n",
      "[2] Loss: 0.0169\n",
      "[3] Loss: 0.0096\n",
      "[4] Loss: 0.0011\n",
      "[5] Loss: 0.0003\n",
      "Validation Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# 3. Load Data\n",
    "train_dir = 'dataset/train'\n",
    "val_dir = 'dataset/val'\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "val_data = datasets.ImageFolder(val_dir, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=8, shuffle=False)\n",
    "\n",
    "class_names = train_data.classes  # ['healthy', 'swollen']\n",
    "\n",
    "# 4. Load Pretrained ResNet\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # 2 classes: healthy, swollen\n",
    "model = model.to(device)\n",
    "\n",
    "# 5. Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 6. Training Loop\n",
    "for epoch in range(5):  # You can increase to 10â€“20\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"[{epoch+1}] Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# 7. Validation Accuracy\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# 8. Save the Model\n",
    "torch.save(model.state_dict(), 'battery_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: swollen\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_image(image_path):\n",
    "    model.eval()\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    return class_names[predicted.item()]\n",
    "\n",
    "# Example:\n",
    "image_path = 'dataset/val/swollen/swollen7.jpeg'\n",
    "result = predict_image(image_path)\n",
    "print(f\"Prediction: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
